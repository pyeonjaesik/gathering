"""
í†µí•© ì‹¤í–‰ í—ˆë¸Œ
- ë°ì´í„° ì¡°íšŒ ë·°ì–´
- ì›ì¬ë£Œëª… ì¶”ì¶œ íŒŒì´í”„ë¼ì¸
- ê³µê³µ API ìˆ˜ì§‘
"""

import os
import json
import socket
import subprocess
import sys
import time
import re
import shutil
import webbrowser
import threading
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

import sqlite3
from app import collector, viewer
from app.backup_tools import create_backup, list_backups, read_backup_metadata, restore_backup, verify_backup
from app.config import DB_FILE
from app.dedupe_tools import (
    duplicate_conditions,
    get_duplicate_samples,
    get_duplicate_stats,
    run_dedupe,
)
from app.database import ensure_processed_food_table
from app.ingredient_enricher import (
    diagnose_analysis,
    get_priority_subcategories,
    run_enricher,
    run_enricher_for_report_no,
)
from app.analyzer import URLIngredientAnalyzer
from app.query_image_benchmark import run_query_image_benchmark_interactive
from app.query_pipeline import (
    cache_serp_images,
    finish_query_run,
    get_image_analysis_cache,
    init_query_pipeline_tables,
    list_next_queries,
    list_recent_runs,
    start_query_run,
    upsert_food_final,
    upsert_image_analysis_cache,
    upsert_query,
)

W = 68
WEB_UI_PORT = 8501
WEB_UI_URL = f"http://localhost:{WEB_UI_PORT}"


def _bar(char: str = "â”€") -> str:
    return "  " + char * (W - 4)


def _display_width(text: str) -> int:
    return sum(2 if ord(c) > 127 else 1 for c in text or "")


def _trunc_display(text: str, max_w: int) -> str:
    result = []
    width = 0
    for c in text or "":
        cw = 2 if ord(c) > 127 else 1
        if width + cw > max_w:
            break
        result.append(c)
        width += cw
    return "".join(result)


def _fixed_display(text: str, max_w: int) -> str:
    t = _trunc_display(text, max_w)
    return t + " " * (max_w - _display_width(t))


def print_header() -> None:
    title = "ğŸ½ï¸ ì‹í’ˆ ë°ì´í„° í†µí•© ì‹¤í–‰ê¸°"
    inner = W - 2
    pad_left = (inner - len(title)) // 2
    pad_right = inner - pad_left - len(title)
    print()
    print("â•”" + "â•" * inner + "â•—")
    print("â•‘" + " " * pad_left + title + " " * pad_right + "â•‘")
    print("â•š" + "â•" * inner + "â•")
    print()


def run_data_viewer() -> None:
    print("\n  ğŸ‘€ [ì‹¤í–‰] ë°ì´í„° ì¡°íšŒ ë·°ì–´ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\n")
    viewer.main()


def _is_port_open(port: int) -> bool:
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
        sock.settimeout(0.3)
        return sock.connect_ex(("127.0.0.1", port)) == 0


def run_web_monitor() -> None:
    if _is_port_open(WEB_UI_PORT):
        print(f"\n  ğŸŒ ì›¹ ëª¨ë‹ˆí„°ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. ë¸Œë¼ìš°ì €ë¥¼ ì—½ë‹ˆë‹¤: {WEB_UI_URL}")
        webbrowser.open_new_tab(WEB_UI_URL)
        return

    project_root = Path(__file__).resolve().parent.parent
    log_path = project_root / "streamlit_web_ui.log"
    env = os.environ.copy()
    env.setdefault("UV_CACHE_DIR", "/tmp/uv-cache")

    cmd = [
        "uv",
        "run",
        "streamlit",
        "run",
        "app/web_ui.py",
        "--server.port",
        str(WEB_UI_PORT),
        "--server.headless",
        "true",
    ]

    print("\n  ğŸš€ ì›¹ ëª¨ë‹ˆí„° ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print(f"  - URL: {WEB_UI_URL}")
    print(f"  - ë¡œê·¸: {log_path}")

    try:
        with open(log_path, "a", encoding="utf-8") as logf:
            subprocess.Popen(  # noqa: S603
                cmd,
                cwd=str(project_root),
                env=env,
                stdout=logf,
                stderr=logf,
                start_new_session=True,
            )
    except FileNotFoundError:
        print("  âŒ uv ëª…ë ¹ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. `uv` ì„¤ì¹˜ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    except Exception as exc:  # pylint: disable=broad-except
        print(f"  âŒ ì›¹ ëª¨ë‹ˆí„° ì‹¤í–‰ ì‹¤íŒ¨: {exc}")
        return

    for _ in range(20):
        if _is_port_open(WEB_UI_PORT):
            print("  âœ… ì›¹ ëª¨ë‹ˆí„° ì¤€ë¹„ ì™„ë£Œ. ë¸Œë¼ìš°ì €ë¥¼ ì—½ë‹ˆë‹¤.")
            webbrowser.open_new_tab(WEB_UI_URL)
            return
        time.sleep(0.5)

    print("  âš ï¸ ì„œë²„ ì‹œì‘ì´ ì§€ì—°ë˜ê³  ìˆìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ URLì„ ì—´ì–´ì£¼ì„¸ìš”.")
    print(f"  ğŸ‘‰ {WEB_UI_URL}")
    print(f"  ğŸ’¡ ë¬¸ì œ í™•ì¸: {log_path}")


def run_image_analyzer_test() -> None:
    print("\n  ğŸ§ª [ì´ë¯¸ì§€ URL analyze í…ŒìŠ¤íŠ¸]")
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        print("  âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    print("  ğŸ”¹ ì…ë ¥ ë°©ë²•:")
    print("    - ì¼ë°˜ URL ì§ì ‘ ì…ë ¥")
    print("    - data URLì€ ê¸¸ì–´ì„œ `paste` ëª¨ë“œ ê¶Œì¥")
    print("    - íŒŒì¼ì—ì„œ ì½ê¸°: @/path/to/data_url.txt")
    raw_input = input("  ğŸ”¹ ì´ë¯¸ì§€ ì…ë ¥(URL / paste / @íŒŒì¼): ").strip()
    image_url = raw_input
    if raw_input.lower() == "paste":
        print("  ğŸ“‹ data URLì„ ë¶™ì—¬ë„£ê³  ë§ˆì§€ë§‰ ì¤„ì— END ì…ë ¥:")
        lines: list[str] = []
        while True:
            line = input()
            if line.strip() == "END":
                break
            lines.append(line.strip())
        image_url = "".join(lines).strip()
    elif raw_input.startswith("@"):
        p = Path(raw_input[1:]).expanduser()
        if not p.exists():
            print(f"  âŒ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {p}")
            return
        image_url = p.read_text(encoding="utf-8").strip()

    # data URLì€ ë³µë¶™ ì‹œ ê³µë°±/ì¤„ë°”ê¿ˆì´ ì„ì¼ ìˆ˜ ìˆì–´ ì œê±°
    if image_url.startswith("data:image/"):
        image_url = re.sub(r"\s+", "", image_url)

    if not image_url:
        print("  âš ï¸ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return

    target_no = input("  ğŸ”¹ íƒ€ê¹ƒ í’ˆëª©ë³´ê³ ë²ˆí˜¸(ì„ íƒ, Enter ìƒëµ): ").strip()
    target_no = target_no or None

    analyzer = URLIngredientAnalyzer(api_key=openai_api_key)
    print("\n  ğŸ” ë¶„ì„ ì¤‘...")
    try:
        result = analyzer.analyze(image_url=image_url, target_item_rpt_no=target_no)
    except Exception as exc:  # pylint: disable=broad-except
        print(f"  âŒ ë¶„ì„ ì‹¤íŒ¨: {exc}")
        return

    print("\n  âœ… [analyze ê²°ê³¼]")
    print(f"  - itemMnftrRptNo : {result.get('itemMnftrRptNo') or 'ì—†ìŒ'}")
    print(f"  - is_flat        : {result.get('is_flat')}")
    print(f"  - is_table_format: {result.get('is_table_format')}")
    print(f"  - has_ingredients: {result.get('has_ingredients')}")
    print(f"  - has_rect_box   : {result.get('has_rect_ingredient_box')}")
    print(f"  - has_report_lbl : {result.get('has_report_label')}")
    print(f"  - product_name   : {result.get('product_name_in_image') or 'ì—†ìŒ'}")
    print(f"  - brand          : {result.get('brand') or 'ì—†ìŒ'}")
    print(f"  - manufacturer   : {result.get('manufacturer') or 'ì—†ìŒ'}")
    print(f"  - note           : {result.get('note') or 'ì—†ìŒ'}")

    ingredients = (result.get("ingredients_text") or "").strip()
    if ingredients:
        preview = ingredients if len(ingredients) <= 240 else ingredients[:240] + "..."
        print(f"  - ingredients    : {preview}")
    else:
        print("  - ingredients    : ì—†ìŒ")

    if target_no:
        status, reason = diagnose_analysis(result, target_no)
        print("\n  ğŸ“Œ [íƒ€ê¹ƒ ê¸°ì¤€ ì§„ë‹¨]")
        print(f"  - target         : {target_no}")
        print(f"  - status         : {status}")
        print(f"  - reason         : {reason}")

    print("\n  ğŸ§¾ [ì›ë³¸ JSON]")
    print(json.dumps(result, ensure_ascii=False, indent=2))


def _latest_benchmark_summary_path() -> Path | None:
    root = Path(__file__).resolve().parent.parent / "validation_reports"
    if not root.exists():
        return None
    candidates = [p / "summary.json" for p in root.glob("benchmark_*") if (p / "summary.json").exists()]
    if not candidates:
        return None
    return max(candidates, key=lambda p: p.stat().st_mtime)


def run_benchmark_menu() -> None:
    while True:
        print("\n  ğŸ“Š [ë²¤ì¹˜ë§ˆí¬]")
        print("    [1] ê²€ìƒ‰ì–´ ê¸°ë°˜ ì´ë¯¸ì§€ ë²¤ì¹˜ë§ˆí¬ (SerpAPI)")
        print("    [b] ë’¤ë¡œê°€ê¸°")
        sub = input("  ğŸ‘‰ ì„ íƒ : ").strip().lower()

        if sub == "1":
            try:
                run_query_image_benchmark_interactive()
            except Exception as exc:  # pylint: disable=broad-except
                print(f"  âŒ ì‹¤í–‰ ì‹¤íŒ¨: {exc}")

        elif sub == "b":
            return
        else:
            print("  âš ï¸ ì˜¬ë°”ë¥¸ ë©”ë‰´ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")


def run_ingredient_menu() -> None:
    if not os.getenv("SERPAPI_KEY"):
        print("\n  âŒ ì˜¤ë¥˜: SERPAPI_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        print('  ğŸ’¡ ì˜ˆ) export SERPAPI_KEY="YOUR_KEY"')
        return

    print("\n  ğŸ§ª [ì›ì¬ë£Œëª… ì¶”ì¶œ ë°©ì‹ ì„ íƒ]")
    print("    [1] ìš°ì„ ìˆœìœ„ ì¤‘ë¶„ë¥˜ì—ì„œ ì„ íƒ")
    print("    [2] í’ˆëª©ë³´ê³ ë²ˆí˜¸ ì§ì ‘ ì…ë ¥ (1ê±´)")
    print("    [b] ì·¨ì†Œ")
    mode = input("  ğŸ‘‰ ì„ íƒ : ").strip().lower()

    if mode == "b":
        print("  â†©ï¸ ì›ì¬ë£Œ ì¶”ì¶œì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
        return

    if mode == "2":
        report_no = input("  ğŸ”¹ í’ˆëª©ë³´ê³ ë²ˆí˜¸ ì…ë ¥: ").strip()
        if not report_no:
            print("  âš ï¸ í’ˆëª©ë³´ê³ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        raw_quiet = input("  ğŸ”¹ ì´ë¯¸ì§€ë³„ ìƒì„¸ ë¡œê·¸ ìƒëµ? [y/N]: ").strip().lower()
        quiet = raw_quiet == "y"
        print("\n  ğŸš€ [ì‹¤í–‰] ì§€ì •í•œ í’ˆëª©ë³´ê³ ë²ˆí˜¸ 1ê±´ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n")
        run_enricher_for_report_no(report_no=report_no, quiet=quiet)
        return

    if mode != "1":
        print("  âš ï¸ ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return

    print("\n  ğŸ§ª [ì›ì¬ë£Œëª… ì¶”ì¶œ ëŒ€ìƒ ì„ íƒ: ì¤‘ë¶„ë¥˜]")
    with sqlite3.connect(DB_FILE) as conn:
        categories = get_priority_subcategories(conn)

    if not categories:
        print("  âš ï¸ ëŒ€ìƒ ì¹´í…Œê³ ë¦¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    col_no = 4
    col_pr = 4
    col_cat = 38
    col_total = 8
    col_attempt = 8
    col_success = 8
    col_rate = 7

    header = (
        f"  {_fixed_display('No', col_no)}  "
        f"{_fixed_display('ìš°ì„ ', col_pr)}  "
        f"{_fixed_display('ëŒ€ë¶„ë¥˜ > ì¤‘ë¶„ë¥˜', col_cat)}  "
        f"{_fixed_display('ì´ìƒí’ˆ', col_total)}  "
        f"{_fixed_display('ì‹œë„ì™„ë£Œ', col_attempt)}  "
        f"{_fixed_display('ì„±ê³µìˆ˜ì§‘', col_success)}  "
        f"{_fixed_display('ìˆ˜ì§‘ë¥ ', col_rate)}"
    )
    print(_bar())
    print(header)
    print(_bar())
    for idx, row in enumerate(categories, 1):
        label = f"{row['lv3']} > {row['lv4']}"
        label = _trunc_display(label, col_cat)
        total_txt = f"{row['total_count']:,}"
        attempted_txt = f"{row['attempted_count']:,}"
        success_txt = f"{row['success_count']:,}"
        rate_txt = f"{row['success_rate']:.1f}%"
        line = (
            f"  {_fixed_display(str(idx), col_no)}  "
            f"{_fixed_display(str(row['priority']), col_pr)}  "
            f"{_fixed_display(label, col_cat)}  "
            f"{_fixed_display(total_txt, col_total)}  "
            f"{_fixed_display(attempted_txt, col_attempt)}  "
            f"{_fixed_display(success_txt, col_success)}  "
            f"{_fixed_display(rate_txt, col_rate)}"
        )
        print(line)
    print(_bar())

    raw_pick = input("  ğŸ‘‰ ì‹¤í–‰í•  ë²ˆí˜¸ ì„ íƒ (b: ì·¨ì†Œ): ").strip().lower()
    if raw_pick == "b":
        print("  â†©ï¸ ì›ì¬ë£Œ ì¶”ì¶œì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
        return
    if not raw_pick.isdigit():
        print("  âš ï¸ ìˆ«ìë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return

    pick = int(raw_pick)
    if pick < 1 or pick > len(categories):
        print("  âš ï¸ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ë²ˆí˜¸ì…ë‹ˆë‹¤.")
        return

    selected = categories[pick - 1]
    print("\n  âš™ï¸ [ì‹¤í–‰ ì˜µì…˜]")
    raw_limit = input("  ğŸ”¹ ì²˜ë¦¬ ìˆ˜ ì…ë ¥ (0 ë˜ëŠ” 'ì „ì²´' = ì „ì²´, ìˆ«ì = ì¼ë¶€) [ê¸°ë³¸ 20]: ").strip()
    raw_quiet = input("  ğŸ”¹ ì´ë¯¸ì§€ë³„ ìƒì„¸ ë¡œê·¸ ìƒëµ? [y/N]: ").strip().lower()

    limit = 20
    if raw_limit:
        normalized = raw_limit.strip().lower()
        if normalized in ("ì „ì²´", "all"):
            limit = 0
        else:
            try:
                limit = int(raw_limit)
                if limit < 0:
                    print("  âš ï¸ ìŒìˆ˜ëŠ” ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 20ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
                    limit = 20
            except ValueError:
                print("  âš ï¸ ì˜ëª»ëœ limit ì…ë ¥ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ 20ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")

    quiet = raw_quiet == "y"

    print("\n  ğŸš€ [ì‹¤í–‰] ì„ íƒí•œ ì¤‘ë¶„ë¥˜ì˜ ì›ì¬ë£Œ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    print(f"  ğŸ¯ ëŒ€ìƒ: {selected['lv3']} > {selected['lv4']}")
    print(
        f"  ğŸ“¦ í˜„í™©: ì´ {selected['total_count']:,} / "
        f"ì‹œë„ {selected['attempted_count']:,} / ì„±ê³µ {selected['success_count']:,} "
        f"({selected['success_rate']:.1f}%)"
    )
    if limit == 0:
        print("  ğŸ§­ ì‹¤í–‰ ë²”ìœ„: ì „ì²´ ëŒ€ìƒ ì²˜ë¦¬")
    else:
        print(f"  ğŸ§­ ì‹¤í–‰ ë²”ìœ„: ìµœëŒ€ {limit:,}ê±´ ì²˜ë¦¬")
    print()
    run_enricher(
        limit=limit,
        quiet=quiet,
        lv3=selected["lv3"],
        lv4=selected["lv4"],
    )


def run_public_api_collection() -> None:
    print("\n  ğŸŒ [ê³µê³µ API ìˆ˜ì§‘ ì„¤ì •]")
    raw = input("  ğŸ”¹ ì €ì¥í•  ë°ì´í„° ê°œìˆ˜ ì…ë ¥ (0 ë˜ëŠ” 'ì „ì²´' = ì „ì²´ ìˆ˜ì§‘): ").strip()
    if not raw:
        print("  âš ï¸ ì…ë ¥ì´ ë¹„ì–´ ìˆì–´ ìˆ˜ì§‘ì„ ì·¨ì†Œí•©ë‹ˆë‹¤.")
        return

    # collector.main()ì€ sys.argvë¥¼ ì½ìœ¼ë¯€ë¡œ ì¼ì‹œì ìœ¼ë¡œ ì£¼ì…
    argv_backup = sys.argv[:]
    try:
        sys.argv = ["collector.py", raw]
        collector.main()
    finally:
        sys.argv = argv_backup


def run_public_api_menu() -> None:
    while True:
        print("\n  ğŸŒ [ê³µê³µ API í•˜ìœ„ ë©”ë‰´]")
        print("    [1] ê°€ê³µì‹í’ˆ ë°ì´í„° ìˆ˜ì§‘")
        print("    [2] ê°€ê³µì‹í’ˆ ì¤‘ë³µ ë°ì´í„° ì ê²€/ì‚­ì œ")
        print("    [b] â†©ï¸ ë’¤ë¡œê°€ê¸°")
        sub = input("  ğŸ‘‰ ì„ íƒ : ").strip().lower()

        if sub == "1":
            run_public_api_collection()
        elif sub == "2":
            run_duplicate_menu()
        elif sub == "b":
            break
        else:
            print("  âš ï¸ ì˜¬ë°”ë¥¸ ë©”ë‰´ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")


def _print_duplicate_stats(stats: dict[str, int]) -> None:
    print("  ğŸ“Š [ì¤‘ë³µ í˜„í™©]")
    print(f"    ì´ ë ˆì½”ë“œ                : {stats['total_rows']:,}")
    print(f"    A(foodCd) ê·¸ë£¹/ì´ˆê³¼í–‰    : {stats['foodCd_groups']:,} / {stats['foodCd_extra']:,}")
    print(f"    B(ì´ë¦„+ìš©ëŸ‰+ì¹´í…Œê³ ë¦¬)    : {stats['h1_groups']:,} / {stats['h1_extra']:,}")
    print(f"    C(ì´ë¦„+ì˜ì–‘+ì¹´í…Œê³ ë¦¬)    : {stats['h2_groups']:,} / {stats['h2_extra']:,}")
    print(f"    D(ì´ë¦„+ì¹´í…Œê³ ë¦¬)         : {stats['h3_groups']:,} / {stats['h3_extra']:,}")


def run_duplicate_menu() -> None:
    while True:
        print("\n  ğŸ§¹ [ì¤‘ë³µ ê´€ë¦¬]")
        print("    [1] ğŸ” ì¤‘ë³µ ì¡°ê±´/í˜„í™© ë³´ê¸°")
        print("    [2] ğŸ—‘ï¸ ì¤‘ë³µ ì‚­ì œ ì‹¤í–‰")
        print("    [b] â†©ï¸ ë’¤ë¡œê°€ê¸°")
        sub = input("  ğŸ‘‰ ì„ íƒ : ").strip().lower()

        if sub == "1":
            print("\n  ğŸ“ [ì¤‘ë³µ íŒì • ì¡°ê±´]")
            for condition in duplicate_conditions():
                print(f"    â€¢ {condition}")
            with sqlite3.connect(DB_FILE) as conn:
                stats = get_duplicate_stats(conn)
                _print_duplicate_stats(stats)
                print("\n  ğŸ§¾ [ì¤‘ë³µ ì˜ì‹¬ ìƒ˜í”Œ 10ê°œ]")
                samples = get_duplicate_samples(conn, limit=10)
                if not samples:
                    print("    âœ… ì—†ìŒ")
                else:
                    for row in samples:
                        food_nm, food_size, serv_size, lv3, lv4, cnt, foodcd_cnt = row
                        print(
                            f"    - {food_nm} | cnt={cnt} foodCd={foodcd_cnt} | "
                            f"size={food_size}, serv={serv_size}, cat={lv3}>{lv4}"
                        )
        elif sub == "2":
            print("\n  âš ï¸ [ì‚­ì œ ì‹¤í–‰ ì „ ì•ˆë‚´]")
            for condition in duplicate_conditions():
                print(f"    â€¢ {condition}")
            with sqlite3.connect(DB_FILE) as conn:
                before = get_duplicate_stats(conn)
            print("\n  ğŸ“Œ [ì‹¤í–‰ ì „ í†µê³„]")
            _print_duplicate_stats(before)
            confirm = input("\n  â“ ìœ„ ì¡°ê±´ìœ¼ë¡œ ì¤‘ë³µ ì‚­ì œë¥¼ ì‹¤í–‰í• ê¹Œìš”? [y/N]: ").strip().lower()
            if confirm != "y":
                print("  ğŸ›‘ ì‚­ì œë¥¼ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
                continue

            try:
                backup_path = create_backup(DB_FILE, label="pre_dedupe")
                print(f"\n  ğŸ’¾ ì•ˆì „ ë°±ì—… ìƒì„± ì™„ë£Œ: {backup_path}")
            except Exception as exc:  # pylint: disable=broad-except
                print(f"\n  âŒ ë°±ì—… ìƒì„± ì‹¤íŒ¨: {exc}")
                continue

            with sqlite3.connect(DB_FILE) as conn:
                result = run_dedupe(conn)
                after = get_duplicate_stats(conn)

            print("\n  âœ… [ì‚­ì œ ê²°ê³¼]")
            print(f"    - ê·œì¹™ A ì‚­ì œ: {result['removed_a']:,}ê±´")
            print(f"    - ê·œì¹™ B ì‚­ì œ: {result['removed_b']:,}ê±´")
            print(f"    - ê·œì¹™ C ì‚­ì œ: {result['removed_c']:,}ê±´")
            print(f"    - ê·œì¹™ D ì‚­ì œ: {result['removed_d']:,}ê±´")
            print(f"    - ì´ ì‚­ì œ   : {result['removed_total']:,}ê±´")
            print(f"    - ì‚­ì œ ëª©ë¡ CSV : {result['csv_path']}")

            print("\n  ğŸ“Œ [ì‹¤í–‰ í›„ í†µê³„]")
            _print_duplicate_stats(after)
        elif sub == "b":
            break
        else:
            print("  âš ï¸ ì˜¬ë°”ë¥¸ ë©”ë‰´ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")


def run_backup_menu() -> None:
    while True:
        print("\n  ğŸ’¾ [ë°±ì—…/ë³µì› ê´€ë¦¬]")
        print("    [1] ë°±ì—… ìƒì„±")
        print("    [2] ë°±ì—… ëª©ë¡ ë³´ê¸°")
        print("    [3] ë°±ì—… ë³µì›")
        print("    [b] â†©ï¸ ë’¤ë¡œê°€ê¸°")
        sub = input("  ğŸ‘‰ ì„ íƒ : ").strip().lower()

        if sub == "1":
            label = input("  ğŸ”¹ ë°±ì—… ë¼ë²¨ [ê¸°ë³¸ manual]: ").strip() or "manual"
            try:
                path = create_backup(DB_FILE, label=label)
                print(f"  âœ… ë°±ì—… ìƒì„± ì™„ë£Œ: {path}")
                drive_dir = os.getenv("GOOGLE_DRIVE_BACKUP_DIR", "").strip()
                if drive_dir:
                    print(f"  â˜ï¸ Google Drive ë³µì‚¬ ì™„ë£Œ: {drive_dir}")
            except Exception as exc:  # pylint: disable=broad-except
                print(f"  âŒ ë°±ì—… ìƒì„± ì‹¤íŒ¨: {exc}")

        elif sub == "2":
            backups = list_backups(DB_FILE)
            print("\n  ğŸ“š [ë°±ì—… ëª©ë¡]")
            if not backups:
                print("    (ë°±ì—… íŒŒì¼ ì—†ìŒ)")
            else:
                for idx, path in enumerate(backups, 1):
                    meta = read_backup_metadata(path)
                    if meta:
                        size_mb = (meta.get("backup_size_bytes") or 0) / (1024 * 1024)
                        mtime = meta.get("backup_mtime") or "-"
                        print(f"    [{idx}] {path}")
                        print(f"         size={size_mb:.1f}MB | mtime={mtime} | meta=ìˆìŒ")
                    else:
                        print(f"    [{idx}] {path}  (meta ì—†ìŒ)")

        elif sub == "3":
            backups = list_backups(DB_FILE)
            if not backups:
                print("  âš ï¸ ë³µì› ê°€ëŠ¥í•œ ë°±ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")
                continue
            print("\n  ğŸ“š [ë³µì› ëŒ€ìƒ ì„ íƒ]")
            for idx, path in enumerate(backups, 1):
                print(f"    [{idx}] {path}")
            raw = input("  ğŸ‘‰ ë³µì›í•  ë²ˆí˜¸ ì…ë ¥ (b: ì·¨ì†Œ): ").strip().lower()
            if raw == "b":
                continue
            if not raw.isdigit():
                print("  âš ï¸ ìˆ«ìë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue
            pick = int(raw)
            if pick < 1 or pick > len(backups):
                print("  âš ï¸ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ë²ˆí˜¸ì…ë‹ˆë‹¤.")
                continue

            target = backups[pick - 1]
            confirm = input(
                "  â— í˜„ì¬ DBë¥¼ í•´ë‹¹ ë°±ì—…ìœ¼ë¡œ ë®ì–´ì”ë‹ˆë‹¤. ê³„ì†í• ê¹Œìš”? [y/N]: "
            ).strip().lower()
            if confirm != "y":
                print("  ğŸ›‘ ë³µì›ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
                continue

            try:
                check = verify_backup(target)
                print(f"  ğŸ” ë°±ì—… ê²€ì¦: integrity={check['sqlite_integrity_ok']} checksum={check['checksum_match']}")
                restored = restore_backup(
                    target,
                    DB_FILE,
                    keep_current_snapshot=True,
                    verify_before_restore=True,
                )
                print(f"  âœ… ë³µì› ì™„ë£Œ: {restored}")
                print("  ğŸ’¾ ê¸°ì¡´ DBëŠ” pre_restore ë¼ë²¨ë¡œ ìë™ ë°±ì—…ë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as exc:  # pylint: disable=broad-except
                print(f"  âŒ ë³µì› ì‹¤íŒ¨: {exc}")

        elif sub == "b":
            break
        else:
            print("  âš ï¸ ì˜¬ë°”ë¥¸ ë©”ë‰´ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")


def run_query_pipeline_menu() -> None:
    while True:
        print("\n  ğŸ§© [ê²€ìƒ‰ì–´ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬]")
        print("    [1] ê²€ìƒ‰ì–´ ì§ì ‘ ì¶”ê°€")
        print("    [2] ìš°ì„ ìˆœìœ„ ëŒ€ê¸° ê²€ìƒ‰ì–´ ë³´ê¸°")
        print("    [3] ìµœê·¼ ì‹¤í–‰ ê¸°ë¡ ë³´ê¸°")
        print("    [4] ê²€ìƒ‰ì–´ ì‹¤í–‰ (SERP -> ë¶„ì„ -> ìµœì¢…ì €ì¥)")
        print("    [b] â†©ï¸ ë’¤ë¡œê°€ê¸°")
        sub = input("  ğŸ‘‰ ì„ íƒ : ").strip().lower()

        if sub == "1":
            query_text = input("  ğŸ”¹ ê²€ìƒ‰ì–´ ì…ë ¥: ").strip()
            if not query_text:
                print("  âš ï¸ ê²€ìƒ‰ì–´ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
                continue
            raw_pri = input("  ğŸ”¹ score(ì ìˆ˜) [ê¸°ë³¸ 0]: ").strip()
            notes = input("  ğŸ”¹ ë©”ëª¨(ì„ íƒ): ").strip() or None
            try:
                pri = float(raw_pri) if raw_pri else 0.0
            except ValueError:
                print("  âš ï¸ ì ìˆ˜ëŠ” ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤.")
                continue

            with sqlite3.connect(DB_FILE) as conn:
                init_query_pipeline_tables(conn)
                query_id = upsert_query(
                    conn,
                    query_text,
                    source="manual",
                    priority_score=pri,
                    target_segment_score=0.0,
                    status="pending",
                    notes=notes,
                )
            print(f"  âœ… ì €ì¥ ì™„ë£Œ: query_id={query_id}")

        elif sub == "2":
            run_query_pool_browser_view()

        elif sub == "3":
            raw = input("  ğŸ”¹ ì¡°íšŒ ê°œìˆ˜ [ê¸°ë³¸ 20]: ").strip()
            limit = 20
            if raw:
                try:
                    limit = max(1, int(raw))
                except ValueError:
                    print("  âš ï¸ ìˆ«ì ì…ë ¥ì´ ì•„ë‹ˆì–´ì„œ ê¸°ë³¸ 20ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    limit = 20
            with sqlite3.connect(DB_FILE) as conn:
                init_query_pipeline_tables(conn)
                rows = list_recent_runs(conn, limit=limit)
            print("\n  ğŸ•˜ [ìµœê·¼ ì‹¤í–‰]")
            if not rows:
                print("    (ì—†ìŒ)")
            else:
                for row in rows:
                    print(
                        f"    - run={row['id']} | query_id={row['query_id']} | status={row['status']} "
                        f"| images={row['analyzed_images']}/{row['total_images']} "
                        f"| saved={row['final_saved_count']} | score={row['overall_score']:.1f}"
                    )
                    print(f"      q={row['query_text']}")

        elif sub == "4":
            run_query_pipeline_execute()

        elif sub == "b":
            break
        else:
            print("  âš ï¸ ì˜¬ë°”ë¥¸ ë©”ë‰´ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")


def run_query_pool_browser_view() -> None:
    with sqlite3.connect(DB_FILE) as conn:
        out_path = viewer.open_query_pool_browser_report(conn)
    print(f"\n  âœ… ê²€ìƒ‰ì–´ í’€ ë¸Œë¼ìš°ì € ë¦¬í¬íŠ¸ ìƒì„±: {out_path}")


def run_query_pipeline_execute() -> None:
    serp_key = os.getenv("SERPAPI_KEY", "").strip()
    openai_key = os.getenv("OPENAI_API_KEY", "").strip()
    if not serp_key:
        print("  âŒ SERPAPI_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return
    if not openai_key:
        print("  âŒ OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    raw_q = input("  ğŸ”¹ ì‹¤í–‰í•  pending ê²€ìƒ‰ì–´ ê°œìˆ˜ [ê¸°ë³¸ 3]: ").strip()
    raw_pages = input("  ğŸ”¹ ê²€ìƒ‰ í˜ì´ì§€ ìˆ˜ [ê¸°ë³¸ 1]: ").strip()
    raw_max_images = input("  ğŸ”¹ ê²€ìƒ‰ì–´ë‹¹ ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜ [ê¸°ë³¸ ì „ì²´=0]: ").strip()
    raw_workers = input("  ğŸ”¹ Pass ë™ì‹œí˜¸ì¶œ ìˆ˜ [ê¸°ë³¸ 5]: ").strip()
    query_limit = int(raw_q) if raw_q.isdigit() else 3
    max_pages = int(raw_pages) if raw_pages.isdigit() else 1
    max_images = int(raw_max_images) if raw_max_images.isdigit() else 0
    pass_workers = int(raw_workers) if raw_workers.isdigit() else 5
    query_limit = max(1, query_limit)
    max_pages = max(1, min(20, max_pages))
    max_images = max(0, max_images)
    pass_workers = max(1, min(50, pass_workers))

    from app.query_image_benchmark import _search_images_all

    with sqlite3.connect(DB_FILE) as conn:
        init_query_pipeline_tables(conn)
        conn.row_factory = sqlite3.Row
        queries = conn.execute(
            """
            SELECT id, query_text, priority_score, status
            FROM query_pool
            WHERE status='pending'
            ORDER BY priority_score DESC, id ASC
            LIMIT ?
            """,
            (query_limit,),
        ).fetchall()

        if not queries:
            print("  âš ï¸ ì‹¤í–‰í•  pending ê²€ìƒ‰ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\n  ğŸš€ ì‹¤í–‰ ì‹œì‘: pending {len(queries)}ê°œ")

        for q in queries:
            query_id = int(q["id"])
            query_text = str(q["query_text"] or "").strip()
            run_id = start_query_run(conn, query_id=query_id)
            print(f"\n  â–¶ query_id={query_id} run_id={run_id}")
            print(f"    q={query_text}")

            analyzed_images = 0
            pass2b_pass_count = 0
            pass4_pass_count = 0
            final_saved_count = 0
            api_calls = 0
            total_images = 0

            try:
                images = _search_images_all(
                    query=query_text,
                    api_key=serp_key,
                    max_pages=max_pages,
                    per_page=100,
                )
                if max_images > 0 and len(images) > max_images:
                    images = images[:max_images]
                total_images = len(images)

                # SERP ìºì‹œ ì €ì¥
                page_map: dict[int, list[dict]] = {}
                for img in images:
                    page_map.setdefault(int(img.page_no), []).append(
                        {
                            "image_url": img.url,
                            "title": img.title,
                            "source": img.source,
                            "rank_in_page": img.rank_in_page,
                        }
                    )
                for page_no, items in page_map.items():
                    cache_serp_images(
                        conn,
                        query_id=query_id,
                        page=page_no,
                        page_size=100,
                        images=items,
                        run_id=run_id,
                    )

                print(f"    ìˆ˜ì§‘ ì´ë¯¸ì§€: {total_images}ê°œ | pass ë™ì‹œí˜¸ì¶œ: {pass_workers}")

                to_process: list[tuple[int, object]] = []
                for idx, img in enumerate(images, 1):
                    cached = get_image_analysis_cache(conn, img.url)
                    if cached and int(cached["pass4_ok"] or 0) == 1:
                        print(f"    [{idx}/{total_images}] ìºì‹œí†µê³¼ ìŠ¤í‚µ")
                        continue
                    to_process.append((idx, img))

                thread_local = threading.local()

                def _get_analyzer() -> URLIngredientAnalyzer:
                    az = getattr(thread_local, "analyzer", None)
                    if az is None:
                        az = URLIngredientAnalyzer(api_key=openai_key)
                        thread_local.analyzer = az
                    return az

                def _analyze_one(idx: int, img_obj: object) -> dict:
                    img_url = str(getattr(img_obj, "url"))
                    az = _get_analyzer()
                    result: dict = {
                        "idx": idx,
                        "url": img_url,
                        "api_calls": 0,
                        "pass2_ok": False,
                        "pass3_ok": False,
                        "pass4_ok": False,
                        "fail_stage": None,
                        "fail_reason": None,
                        "p2a_ok": False,
                        "p2b_ok": False,
                        "raw_pass2a": None,
                        "raw_pass2b": None,
                        "raw_pass3": None,
                        "raw_pass4": None,
                        "product_name": None,
                        "report_no": None,
                        "ingredients_text": None,
                        "nutrition_text": None,
                    }

                    pass2 = az.analyze_pass2(image_url=img_url, target_item_rpt_no=None)
                    result["api_calls"] += 1
                    qf = pass2.get("quality_flags") or {}
                    p2a_ok = bool(qf.get("pass2a_ok"))
                    p2b_ok = bool(qf.get("pass2b_pass"))
                    gate_ok = bool(pass2.get("quality_gate_pass"))
                    decision = str(pass2.get("ai_decision") or "").upper()
                    pass2_ok = gate_ok and p2a_ok and p2b_ok and decision == "READ"
                    result["p2a_ok"] = p2a_ok
                    result["p2b_ok"] = p2b_ok
                    result["raw_pass2a"] = pass2.get("raw_model_text_pass2a")
                    result["raw_pass2b"] = pass2.get("raw_model_text_pass2b")

                    if not pass2_ok:
                        result["fail_stage"] = "pass2"
                        result["fail_reason"] = (
                            "|".join(str(x) for x in (pass2.get("quality_fail_reasons") or []))
                            or str(pass2.get("ai_decision_reason") or "pass2_fail")
                        )
                        return result

                    result["pass2_ok"] = True
                    pass3 = az.analyze_pass3(
                        image_url=img_url,
                        target_item_rpt_no=None,
                        include_nutrition=bool(qf.get("has_nutrition_section")),
                    )
                    result["api_calls"] += 1
                    result["raw_pass3"] = pass3.get("raw_model_text_pass3_ingredients")
                    pass3_err = str(pass3.get("error") or "").strip()
                    if pass3_err:
                        result["fail_stage"] = "pass3"
                        result["fail_reason"] = pass3_err
                        return result

                    product_name = (pass3.get("product_name_in_image") or "").strip()
                    report_no = (pass3.get("product_report_number") or "").strip()
                    ingredients_text = (pass3.get("ingredients_text") or "").strip()
                    nutrition_text = (pass3.get("nutrition_text") or "").strip() or None
                    if not (product_name and report_no and ingredients_text):
                        result["fail_stage"] = "pass3"
                        result["fail_reason"] = "required_fields_missing"
                        return result

                    result["pass3_ok"] = True
                    result["product_name"] = product_name
                    result["report_no"] = report_no
                    result["ingredients_text"] = ingredients_text
                    result["nutrition_text"] = nutrition_text

                    pass4 = az.analyze_pass4_normalize(
                        pass2_result=pass2,
                        pass3_result=pass3,
                        target_item_rpt_no=None,
                    )
                    result["api_calls"] += 1
                    result["raw_pass4"] = pass4.get("raw_model_text_pass4_ingredients")
                    pass4_err = str(pass4.get("pass4_ai_error") or "").strip()
                    if pass4_err:
                        result["fail_stage"] = "pass4"
                        result["fail_reason"] = pass4_err or "pass4_fail"
                        return result

                    result["pass4_ok"] = True
                    return result

                done_count = 0
                with ThreadPoolExecutor(max_workers=pass_workers) as ex:
                    fut_map = {ex.submit(_analyze_one, idx, img): idx for idx, img in to_process}
                    for fut in as_completed(fut_map):
                        res = fut.result()
                        idx = int(res["idx"])
                        done_count += 1
                        analyzed_images += 1
                        api_calls += int(res.get("api_calls", 0))
                        print(f"    [{idx}/{total_images}] ì™„ë£Œ ({done_count}/{len(to_process)})")

                        if not bool(res.get("pass2_ok")):
                            upsert_image_analysis_cache(
                                conn,
                                image_url=str(res["url"]),
                                run_id=run_id,
                                pass1_ok=None,
                                pass2a_ok=bool(res.get("p2a_ok")),
                                pass2b_ok=bool(res.get("p2b_ok")),
                                pass3_ok=False,
                                pass4_ok=False,
                                fail_stage=str(res.get("fail_stage") or "pass2"),
                                fail_reason=str(res.get("fail_reason") or "pass2_fail"),
                                raw_pass2a=res.get("raw_pass2a"),
                                raw_pass2b=res.get("raw_pass2b"),
                            )
                            continue

                        pass2b_pass_count += 1

                        if not bool(res.get("pass3_ok")):
                            upsert_image_analysis_cache(
                                conn,
                                image_url=str(res["url"]),
                                run_id=run_id,
                                pass1_ok=None,
                                pass2a_ok=bool(res.get("p2a_ok")),
                                pass2b_ok=bool(res.get("p2b_ok")),
                                pass3_ok=False,
                                pass4_ok=False,
                                fail_stage=str(res.get("fail_stage") or "pass3"),
                                fail_reason=str(res.get("fail_reason") or "pass3_fail"),
                                raw_pass2a=res.get("raw_pass2a"),
                                raw_pass2b=res.get("raw_pass2b"),
                                raw_pass3=res.get("raw_pass3"),
                            )
                            continue

                        if not bool(res.get("pass4_ok")):
                            upsert_image_analysis_cache(
                                conn,
                                image_url=str(res["url"]),
                                run_id=run_id,
                                pass1_ok=None,
                                pass2a_ok=bool(res.get("p2a_ok")),
                                pass2b_ok=bool(res.get("p2b_ok")),
                                pass3_ok=True,
                                pass4_ok=False,
                                fail_stage=str(res.get("fail_stage") or "pass4"),
                                fail_reason=str(res.get("fail_reason") or "pass4_fail"),
                                raw_pass2a=res.get("raw_pass2a"),
                                raw_pass2b=res.get("raw_pass2b"),
                                raw_pass3=res.get("raw_pass3"),
                                raw_pass4=res.get("raw_pass4"),
                            )
                            continue

                        pass4_pass_count += 1
                        upsert_food_final(
                            conn,
                            product_name=str(res.get("product_name") or ""),
                            item_mnftr_rpt_no=str(res.get("report_no") or ""),
                            ingredients_text=str(res.get("ingredients_text") or ""),
                            nutrition_text=res.get("nutrition_text"),
                            nutrition_source="pass3",
                            source_image_url=str(res["url"]),
                            source_query_id=query_id,
                            source_run_id=run_id,
                        )
                        final_saved_count += 1

                        upsert_image_analysis_cache(
                            conn,
                            image_url=str(res["url"]),
                            run_id=run_id,
                            pass1_ok=None,
                            pass2a_ok=bool(res.get("p2a_ok")),
                            pass2b_ok=bool(res.get("p2b_ok")),
                            pass3_ok=True,
                            pass4_ok=True,
                            fail_stage=None,
                            fail_reason=None,
                            raw_pass2a=res.get("raw_pass2a"),
                            raw_pass2b=res.get("raw_pass2b"),
                            raw_pass3=res.get("raw_pass3"),
                            raw_pass4=res.get("raw_pass4"),
                        )

                finish_query_run(
                    conn,
                    run_id=run_id,
                    status="done",
                    total_images=total_images,
                    analyzed_images=analyzed_images,
                    pass2b_pass_count=pass2b_pass_count,
                    pass4_pass_count=pass4_pass_count,
                    final_saved_count=final_saved_count,
                    api_calls=api_calls,
                )
                print(
                    f"    âœ… ì™„ë£Œ: analyzed={analyzed_images}, pass2b={pass2b_pass_count}, "
                    f"pass4={pass4_pass_count}, saved={final_saved_count}"
                )
            except Exception as exc:  # pylint: disable=broad-except
                finish_query_run(
                    conn,
                    run_id=run_id,
                    status="failed",
                    total_images=total_images,
                    analyzed_images=analyzed_images,
                    pass2b_pass_count=pass2b_pass_count,
                    pass4_pass_count=pass4_pass_count,
                    final_saved_count=final_saved_count,
                    api_calls=api_calls,
                    error_message=str(exc),
                )
                print(f"    âŒ ì‹¤íŒ¨: {exc}")


def main() -> None:
    try:
        with sqlite3.connect(DB_FILE) as _conn:
            ensure_processed_food_table(_conn)
    except sqlite3.Error:
        pass

    while True:
        print_header()
        print(_bar())
        print("  ğŸ›ï¸ [ ë©”ì¸ ë©”ë‰´ ]")
        print("    [1] ğŸ‘€ ë°ì´í„° ì¡°íšŒ/íƒìƒ‰ (ì‹ ê·œ viewer)")
        print("    [2] ğŸŒ ê³µê³µ API ê´€ë¦¬ (ê°€ê³µì‹í’ˆ)")
        print("    [3] ğŸ’¾ ë°±ì—…/ë³µì› ê´€ë¦¬")
        print("    [4] ğŸ“Š analyze ë²¤ì¹˜ë§ˆí¬ ë„ìš°ë¯¸")
        print("    [5] ğŸ§© ê²€ìƒ‰ì–´ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬")
        print("    [q] ğŸšª ì¢…ë£Œ")
        print(_bar())
        choice = input("  ğŸ‘‰ ì„ íƒ : ").strip().lower()

        if choice == "1":
            run_data_viewer()
        elif choice == "2":
            run_public_api_menu()
        elif choice == "3":
            run_backup_menu()
        elif choice == "4":
            run_benchmark_menu()
        elif choice == "5":
            run_query_pipeline_menu()
        elif choice == "q":
            print("\n  ğŸ‘‹ ì‹¤í–‰ê¸°ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n")
            break
        else:
            print("\n  âš ï¸ ì˜¬ë°”ë¥¸ ë©”ë‰´ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n")


if __name__ == "__main__":
    main()
