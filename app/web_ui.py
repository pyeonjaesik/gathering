"""
ë¸Œë¼ìš°ì € ê¸°ë°˜ ì›ì¬ë£Œ ìˆ˜ì§‘ ëª¨ë‹ˆí„°.

ì‹¤í–‰:
    uv run streamlit run app/web_ui.py
"""

from __future__ import annotations

import json
import sqlite3
import sys
import threading
import time
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Any

import streamlit as st

# Streamlit ì‹¤í–‰ ì‹œ ëª¨ë“ˆ ê²½ë¡œê°€ app/ë¡œ ì¡íˆëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€.
PROJECT_ROOT = Path(__file__).resolve().parent.parent
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from app.config import DB_FILE
from app.ingredient_enricher import diagnose_analysis, get_priority_subcategories, run_enricher


@dataclass
class RunJob:
    limit: int
    quiet: bool
    lv3: str | None
    lv4: str | None


def _conn() -> sqlite3.Connection:
    conn = sqlite3.connect(DB_FILE)
    conn.row_factory = sqlite3.Row
    return conn


def _fmt_dt(value: str | None) -> str:
    if not value:
        return "-"
    return value


def _safe_json(text: str | None) -> dict[str, Any]:
    if not text:
        return {}
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        return {}


def _ensure_state() -> None:
    if "run_thread" not in st.session_state:
        st.session_state.run_thread = None
    if "run_status" not in st.session_state:
        st.session_state.run_status = {
            "running": False,
            "started_at": None,
            "finished_at": None,
            "error": None,
            "last_job": None,
        }


def _is_running() -> bool:
    th = st.session_state.run_thread
    return bool(th and th.is_alive())


def _runner(job: RunJob) -> None:
    st.session_state.run_status["running"] = True
    st.session_state.run_status["error"] = None
    st.session_state.run_status["started_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.session_state.run_status["finished_at"] = None
    st.session_state.run_status["last_job"] = job
    try:
        run_enricher(
            limit=job.limit,
            quiet=job.quiet,
            lv3=job.lv3,
            lv4=job.lv4,
        )
    except Exception as exc:  # pylint: disable=broad-except
        st.session_state.run_status["error"] = str(exc)
    finally:
        st.session_state.run_status["running"] = False
        st.session_state.run_status["finished_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def _start_job(job: RunJob) -> None:
    if _is_running():
        return
    thread = threading.Thread(target=_runner, args=(job,), daemon=True)
    st.session_state.run_thread = thread
    thread.start()


def _load_overview(conn: sqlite3.Connection) -> dict[str, int]:
    total_target = conn.execute(
        """
        SELECT COUNT(DISTINCT itemMnftrRptNo)
        FROM processed_food_info
        WHERE itemMnftrRptNo IS NOT NULL AND itemMnftrRptNo != ''
        """
    ).fetchone()[0]
    info_cnt = conn.execute("SELECT COUNT(*) FROM ingredient_info").fetchone()[0]
    attempt_total = conn.execute("SELECT COUNT(*) FROM ingredient_attempts").fetchone()[0]
    matched = conn.execute(
        "SELECT COUNT(*) FROM ingredient_attempts WHERE status='matched'"
    ).fetchone()[0]
    unmatched = conn.execute(
        "SELECT COUNT(*) FROM ingredient_attempts WHERE status='unmatched'"
    ).fetchone()[0]
    failed = conn.execute(
        "SELECT COUNT(*) FROM ingredient_attempts WHERE status='failed'"
    ).fetchone()[0]
    in_progress = conn.execute(
        "SELECT COUNT(*) FROM ingredient_attempts WHERE status='in_progress'"
    ).fetchone()[0]
    return {
        "total_target": total_target,
        "info_cnt": info_cnt,
        "attempt_total": attempt_total,
        "matched": matched,
        "unmatched": unmatched,
        "failed": failed,
        "in_progress": in_progress,
    }


def _load_in_progress(conn: sqlite3.Connection) -> list[sqlite3.Row]:
    return conn.execute(
        """
        SELECT
          ia.query_itemMnftrRptNo,
          ia.query_food_name,
          ia.query_mfr_name,
          ia.searched_query,
          ia.images_requested,
          ia.images_analyzed,
          ia.started_at,
          (
            SELECT COUNT(*)
            FROM ingredient_extractions ie
            WHERE ie.query_itemMnftrRptNo = ia.query_itemMnftrRptNo
          ) AS analyzed_rows
        FROM ingredient_attempts ia
        WHERE ia.status = 'in_progress'
        ORDER BY ia.started_at DESC
        """
    ).fetchall()


def _load_recent_logs(conn: sqlite3.Connection, limit: int = 100) -> list[dict[str, Any]]:
    rows = conn.execute(
        """
        SELECT
          ie.query_itemMnftrRptNo,
          ie.query_food_name,
          ie.image_rank,
          ie.image_url,
          ie.extracted_itemMnftrRptNo,
          ie.ingredients_text,
          ie.matched_target,
          ie.raw_payload,
          ie.created_at
        FROM ingredient_extractions ie
        ORDER BY ie.id DESC
        LIMIT ?
        """,
        (limit,),
    ).fetchall()

    items: list[dict[str, Any]] = []
    for row in rows:
        payload = _safe_json(row["raw_payload"])
        status_label, reason = diagnose_analysis(payload, row["query_itemMnftrRptNo"])
        ingredients = row["ingredients_text"] or ""
        items.append(
            {
                "ì‹œê°": row["created_at"],
                "ì§ˆì˜ë²ˆí˜¸": row["query_itemMnftrRptNo"],
                "ìƒí’ˆëª…": row["query_food_name"],
                "rank": row["image_rank"],
                "ì´ë¯¸ì§€URL": row["image_url"],
                "ì¶”ì¶œë²ˆí˜¸": row["extracted_itemMnftrRptNo"] or "-",
                "ë§¤ì¹­": "YES" if row["matched_target"] == 1 else "NO",
                "ìƒíƒœ": status_label,
                "ì‚¬ìœ ": reason,
                "ì›ì¬ë£Œì¶”ì¶œ": (ingredients[:120] + "...") if len(ingredients) > 120 else (ingredients or "-"),
                "ì›ì¬ë£Œì „ì²´": ingredients or "-",
            }
        )
    return items


def _load_live_processing_rows(conn: sqlite3.Connection, limit: int = 200) -> list[dict[str, Any]]:
    """í˜„ì¬ in_progress ëŒ€ìƒì—ì„œ ë°©ê¸ˆ ë¶„ì„ëœ ì´ë¯¸ì§€ ë¡œê·¸ë¥¼ ì‹¤ì‹œê°„ ì¡°íšŒ."""
    rows = conn.execute(
        """
        SELECT
          ie.query_itemMnftrRptNo,
          ie.query_food_name,
          ie.image_rank,
          ie.image_url,
          ie.extracted_itemMnftrRptNo,
          ie.ingredients_text,
          ie.matched_target,
          ie.raw_payload,
          ie.created_at
        FROM ingredient_extractions ie
        JOIN ingredient_attempts ia
          ON ia.query_itemMnftrRptNo = ie.query_itemMnftrRptNo
        WHERE ia.status = 'in_progress'
        ORDER BY ie.id DESC
        LIMIT ?
        """,
        (limit,),
    ).fetchall()

    result: list[dict[str, Any]] = []
    for row in rows:
        payload = _safe_json(row["raw_payload"])
        status_label, reason = diagnose_analysis(payload, row["query_itemMnftrRptNo"])
        ingredients = row["ingredients_text"] or ""
        result.append(
            {
                "ì‹œê°": row["created_at"],
                "ì§ˆì˜ë²ˆí˜¸": row["query_itemMnftrRptNo"],
                "ìƒí’ˆëª…": row["query_food_name"],
                "ì´ë¯¸ì§€ìˆœë²ˆ": row["image_rank"],
                "ì´ë¯¸ì§€URL": row["image_url"],
                "ì¶”ì¶œë²ˆí˜¸": row["extracted_itemMnftrRptNo"] or "-",
                "ë§¤ì¹­": "YES" if row["matched_target"] == 1 else "NO",
                "ìƒíƒœ": status_label,
                "ì‚¬ìœ ": reason,
                "ì›ì¬ë£Œ": (ingredients[:100] + "...") if len(ingredients) > 100 else (ingredients or "-"),
            }
        )
    return result


def _load_priority_df(conn: sqlite3.Connection) -> list[dict[str, Any]]:
    categories = get_priority_subcategories(conn)
    result: list[dict[str, Any]] = []
    for idx, row in enumerate(categories, start=1):
        result.append(
            {
                "No": idx,
                "ìš°ì„ ìˆœìœ„": row["priority"],
                "ëŒ€ë¶„ë¥˜": row["lv3"],
                "ì¤‘ë¶„ë¥˜": row["lv4"],
                "ì´ìƒí’ˆ": row["total_count"],
                "ì‹œë„ì™„ë£Œ": row["attempted_count"],
                "ì„±ê³µìˆ˜ì§‘": row["success_count"],
                "ìˆ˜ì§‘ë¥ (%)": round(row["success_rate"], 1),
            }
        )
    return result


def main() -> None:
    st.set_page_config(
        page_title="ì›ì¬ë£Œ ë¶„ì„ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°",
        page_icon="ğŸ§ª",
        layout="wide",
    )
    _ensure_state()

    st.title("ğŸ§ª ì›ì¬ë£Œ ë¶„ì„ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°")
    st.caption("ì¹´í…Œê³ ë¦¬ ì„ íƒ í›„ ì‹¤í–‰í•˜ë©´ DB ê¸°ì¤€ìœ¼ë¡œ ì§„í–‰ìƒí™©/ì‹¤íŒ¨ì‚¬ìœ /ì´ë¯¸ì§€ URLì„ ì‹¤ì‹œê°„ ì¶”ì í•©ë‹ˆë‹¤.")

    conn = _conn()
    overview = _load_overview(conn)

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ì „ì²´ ëŒ€ìƒ(ê³ ìœ  í’ˆëª©ë²ˆí˜¸)", f"{overview['total_target']:,}")
    c2.metric("ì›ì¬ë£Œ í™•ë³´", f"{overview['info_cnt']:,}")
    c3.metric("ì‹œë„ ì´ë ¥", f"{overview['attempt_total']:,}")
    c4.metric("ì§„í–‰ì¤‘", f"{overview['in_progress']:,}")

    c5, c6, c7 = st.columns(3)
    c5.metric("matched", f"{overview['matched']:,}")
    c6.metric("unmatched", f"{overview['unmatched']:,}")
    c7.metric("failed", f"{overview['failed']:,}")

    with st.expander("âš™ï¸ ì‹¤í–‰ ì„¤ì •", expanded=True):
        categories = _load_priority_df(conn)
        labels = [f"{r['No']:>3}. {r['ìš°ì„ ìˆœìœ„']} | {r['ëŒ€ë¶„ë¥˜']} > {r['ì¤‘ë¶„ë¥˜']} (ì´ {r['ì´ìƒí’ˆ']:,})" for r in categories]
        pick = st.selectbox("ì¤‘ë¶„ë¥˜ ì„ íƒ", options=list(range(len(labels))), format_func=lambda i: labels[i])
        selected = categories[pick]

        all_mode = st.checkbox("ì „ì²´ ì²˜ë¦¬(ë‚¨ì€ ëŒ€ìƒ ì „ë¶€)", value=False)
        limit = 0 if all_mode else st.number_input("ì²˜ë¦¬ ê°œìˆ˜", min_value=1, value=20, step=1)
        quiet = st.checkbox("ì´ë¯¸ì§€ë³„ ìƒì„¸ ë¡œê·¸ ì¶•ì•½(quiet)", value=False)

        running = _is_running()
        if running:
            st.warning("í˜„ì¬ ìˆ˜ì§‘ ì‘ì—…ì´ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. ì¤‘ë³µ ì‹¤í–‰ì€ ë§‰ì•„ë‘¡ë‹ˆë‹¤.")
        start = st.button("ğŸš€ ì„ íƒ ì¹´í…Œê³ ë¦¬ ì‹¤í–‰", disabled=running)
        if start:
            _start_job(
                RunJob(
                    limit=int(limit),
                    quiet=bool(quiet),
                    lv3=selected["ëŒ€ë¶„ë¥˜"],
                    lv4=selected["ì¤‘ë¶„ë¥˜"],
                )
            )
            st.success("ì‘ì—…ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ì‹¤ì‹œê°„ íŒ¨ë„ì—ì„œ ì§„í–‰ìƒí™©ì„ í™•ì¸í•˜ì„¸ìš”.")

    status = st.session_state.run_status
    st.subheader("ğŸ“¡ ì‹¤í–‰ ìƒíƒœ")
    st.write(
        {
            "running": _is_running(),
            "started_at": _fmt_dt(status.get("started_at")),
            "finished_at": _fmt_dt(status.get("finished_at")),
            "error": status.get("error") or "-",
        }
    )

    st.subheader("ğŸ”„ í˜„ì¬ ì§„í–‰ì¤‘ ìƒí’ˆ")
    in_progress = _load_in_progress(conn)
    if not in_progress:
        st.info("ì§„í–‰ì¤‘ì¸ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        table: list[dict[str, Any]] = []
        for row in in_progress:
            done = row["analyzed_rows"] or 0
            req = row["images_requested"] or 0
            table.append(
                {
                    "í’ˆëª©ë²ˆí˜¸": row["query_itemMnftrRptNo"],
                    "ìƒí’ˆëª…": row["query_food_name"],
                    "ì œì¡°ì‚¬": row["query_mfr_name"] or "-",
                    "ê²€ìƒ‰ì–´": row["searched_query"] or "-",
                    "ì´ë¯¸ì§€ì²˜ë¦¬": f"{done}/{req if req else '-'}",
                    "ì‹œì‘ì‹œê°": row["started_at"],
                }
            )
        st.dataframe(table, use_container_width=True, hide_index=True)

    st.subheader("âš¡ ì§€ê¸ˆ ë¶„ì„ì¤‘ì¸ ì´ë¯¸ì§€ ë¡œê·¸ (ì‹¤ì‹œê°„)")
    live_rows = _load_live_processing_rows(conn, limit=300)
    if not live_rows:
        st.info("í˜„ì¬ in_progress ëŒ€ìƒì˜ ì´ë¯¸ì§€ ë¶„ì„ ë¡œê·¸ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.dataframe(
            live_rows,
            use_container_width=True,
            hide_index=True,
            column_config={
                "ì´ë¯¸ì§€URL": st.column_config.LinkColumn("ì´ë¯¸ì§€URL", display_text="ì—´ê¸°"),
            },
        )

    st.subheader("ğŸ§¾ ìµœê·¼ ì´ë¯¸ì§€ ë¶„ì„ ë¡œê·¸")
    logs = _load_recent_logs(conn, limit=180)
    if not logs:
        st.info("ì•„ì§ ë¶„ì„ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.markdown("#### ğŸ–¼ï¸ ì‹¤ì‹œê°„ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°")
        st.caption("ìµœê·¼ ë¶„ì„ëœ ì´ë¯¸ì§€ë¥¼ í´ë¦­ ì—†ì´ ë°”ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        preview_count = st.slider("ë¯¸ë¦¬ë³´ê¸° ê°œìˆ˜", min_value=3, max_value=18, value=9, step=3)
        cols_per_row = 3
        preview_logs = logs[:preview_count]
        for i in range(0, len(preview_logs), cols_per_row):
            cols = st.columns(cols_per_row)
            chunk = preview_logs[i : i + cols_per_row]
            for col, item in zip(cols, chunk):
                with col:
                    st.image(item["ì´ë¯¸ì§€URL"], use_container_width=True)
                    st.caption(
                        f"{item['ì‹œê°']} | #{item['rank']} | {item['ìƒíƒœ']}"
                    )
                    st.write(f"**ì§ˆì˜ë²ˆí˜¸**: `{item['ì§ˆì˜ë²ˆí˜¸']}`")
                    st.write(f"**ì¶”ì¶œë²ˆí˜¸**: `{item['ì¶”ì¶œë²ˆí˜¸']}` | **ë§¤ì¹­**: {item['ë§¤ì¹­']}")
                    st.write(f"**ì‚¬ìœ **: {item['ì‚¬ìœ ']}")
                    st.write(f"**ì›ì¬ë£Œ**: {item['ì›ì¬ë£Œì¶”ì¶œ']}")
                    with st.expander("ì›ì¬ë£Œ ì „ì²´ í…ìŠ¤íŠ¸ / URL"):
                        st.code(item["ì›ì¬ë£Œì „ì²´"])
                        st.code(item["ì´ë¯¸ì§€URL"])

        st.markdown("#### ğŸ“‹ ìµœê·¼ ë¡œê·¸ í…Œì´ë¸”")
        st.dataframe(
            logs,
            use_container_width=True,
            hide_index=True,
            column_config={
                "ì´ë¯¸ì§€URL": st.column_config.LinkColumn("ì´ë¯¸ì§€URL", display_text="ì—´ê¸°"),
            },
        )

    conn.close()

    auto_refresh = st.checkbox("2ì´ˆ ìë™ ìƒˆë¡œê³ ì¹¨", value=True)
    if auto_refresh and _is_running():
        time.sleep(2)
        st.rerun()


if __name__ == "__main__":
    main()
